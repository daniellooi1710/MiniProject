{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weekly activity\n",
    "1. Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use _\"lena.jfif\"_ as the input image.\n",
    "    - Use external libraries `imutils`.  \n",
    "    - Modify the transformation matrix.\n",
    "2. Use the images with titles: _\"flower.jfif\"_ and _\"native-bee.png\"_. I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are `cv.bitwise_and()`, `cv.bitwise_or()` and `cv.bitwise_not()`. You need to use `cv.threshold` function to segment the flower. Please refer to [online documentation](https://docs.opencv.org/4.x/d0/d86/tutorial_py_image_arithmetics.html) for more info. The result should resemble the following:  \n",
    "![bee and flowers](img_embed/activity3.PNG \"bee_flower\")\n",
    "3. Write a function that randomly crop the central region of an image. The method signature should be as shown in the following:\n",
    "```\n",
    "random_center_crop(image, min_crop_ratio, max_crop_ratio)\n",
    "```\n",
    "\n",
    "4. Aside from Gaussian noise, name another common type of noise. Write the code to demonstrate how the noise can be included in an image."
   ],
   "id": "29440063443f2462"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T14:23:18.249411Z",
     "start_time": "2024-08-11T14:23:17.943642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2 as cv\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "from utils import display_image"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Question 1**",
   "id": "209b0e929ff32a05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T10:20:44.677833Z",
     "start_time": "2024-08-11T10:20:44.675325Z"
    }
   },
   "cell_type": "code",
   "source": "image = cv.imread(\"images/lena.jfif\")",
   "id": "c76d9d5fd7515908",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T12:21:55.206624Z",
     "start_time": "2024-08-11T12:21:54.272405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Method 1\n",
    "img_rotated = imutils.rotate_bound(image, 45)\n",
    "\n",
    "display_image(\"rotated image (imutils)\", img_rotated)"
   ],
   "id": "53df3ecb94bb2614",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T12:22:29.138619Z",
     "start_time": "2024-08-11T12:22:26.773764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Method 2\n",
    "def rotate_image_no_crop(image, angle):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # calculate rotation parameters\n",
    "    theta = np.radians(angle)\n",
    "    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n",
    "\n",
    "    # determine new width and height of image\n",
    "    new_width = int(width * abs(cos_theta) + height * abs(sin_theta))\n",
    "    new_height = int(width * abs(sin_theta) + height * abs(cos_theta))\n",
    "\n",
    "    # create a larger canvas and center the image\n",
    "    enlarged_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "    offset_x, offset_y = (new_width - width) // 2, (new_height - height) // 2\n",
    "    enlarged_image[offset_y:offset_y + height, offset_x:offset_x + width] = image\n",
    "    \n",
    "    # find center of new image and calculate rotation matrix\n",
    "    cx, cy = new_width // 2, new_height // 2\n",
    "    rotation_matrix = np.array([[cos_theta, -sin_theta, cx * (1 - cos_theta) + cy * sin_theta],\n",
    "                                [sin_theta, cos_theta, cy * (1 - cos_theta) - cx * sin_theta]])\n",
    "\n",
    "    # apply transformation\n",
    "    rotated_image = cv.warpAffine(enlarged_image, rotation_matrix, (new_width, new_height))\n",
    "\n",
    "    return rotated_image\n",
    "\n",
    "rotated_image = rotate_image_no_crop(image, 45)\n",
    "\n",
    "display_image(\"rotated image (transformation matrix\", rotated_image)"
   ],
   "id": "ef9237188970c330",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Question 2**",
   "id": "4ad879d7e0699928"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T13:55:30.690521Z",
     "start_time": "2024-08-11T13:55:30.681396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img = cv.imread(\"images/flower.jfif\")\n",
    "target_img = cv.imread(\"images/native-bee.png\")\n",
    "img.shape"
   ],
   "id": "72b3c828da95646d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 275, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T14:08:00.906191Z",
     "start_time": "2024-08-11T14:04:03.383553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "enlarged_img = np.zeros((target_img.shape[0], target_img.shape[1], 3), dtype=np.uint8)\n",
    "enlarged_img[0:img.shape[0], 0:img.shape[1]] = img\n",
    "    \n",
    "src_mask = cv.cvtColor(enlarged_img, cv.COLOR_BGR2GRAY)\n",
    "_, src_mask = cv.threshold(src_mask, 1, 255, cv.THRESH_BINARY)\n",
    "\n",
    "src_mask_inv = cv.bitwise_not(src_mask)\n",
    "\n",
    "roi = cv.bitwise_and(enlarged_img, enlarged_img, src_mask)\n",
    "\n",
    "overlay = cv.addWeighted(target_img, 1, roi, 1, 0)\n",
    "\n",
    "display_image(\"overlay\", overlay)"
   ],
   "id": "5b0e7a2f282466ba",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Question 3**",
   "id": "d5687c5255c0b7db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T14:23:13.290036Z",
     "start_time": "2024-08-11T14:23:13.286531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def random_center_crop(img, min_crop_ratio, max_crop_ratio):\n",
    "    if not (0.0 <= min_crop_ratio <= max_crop_ratio <= 1.0):\n",
    "        raise ValueError(\"Invalid crop ratios. Ensure 0.0 <= min_crop_ratio <= max_crop_ratio <= 1.0.\")\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "    crop_size = np.random.uniform(min_crop_ratio, max_crop_ratio)\n",
    "\n",
    "    crop_h, crop_w = int(height * crop_size), int(width * crop_size)\n",
    "    offset_x = (width - crop_w) // 2\n",
    "    offset_y = (height - crop_h) // 2\n",
    "\n",
    "    cropped_img = img[offset_y:offset_y + crop_h, offset_x:offset_x + crop_w]\n",
    "    display_image(\"random crop\", cropped_img)"
   ],
   "id": "623ad8922210120",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T14:23:32.205821Z",
     "start_time": "2024-08-11T14:23:31.790183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage:\n",
    "input_image = cv.imread(\"images/lena.png\")\n",
    "cropped_image = random_center_crop(input_image, min_crop_ratio=0.2, max_crop_ratio=0.8)"
   ],
   "id": "8cc5512be2e968c1",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Question 4**\n",
    "\n",
    "Answer: Salt and pepper noise"
   ],
   "id": "cc8a47940ab79f44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-11T14:57:01.025341Z",
     "start_time": "2024-08-11T14:56:59.738009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def salt_and_pepper(img, noise_amt):\n",
    "    noisy_img = np.copy(img)\n",
    "    height, width = noisy_img.shape[:2]\n",
    "    num_pixels = int(noise_amt * height * width)\n",
    "\n",
    "    salt = np.random.randint(0, height, num_pixels), np.random.randint(0, width, num_pixels)\n",
    "    noisy_img[salt] = [255,255,255]\n",
    "\n",
    "    pepper = np.random.randint(0, height, num_pixels), np.random.randint(0, width, num_pixels)\n",
    "    noisy_img[pepper] = [0,0,0]\n",
    "\n",
    "    display_image(\"noisy image\", noisy_img)\n",
    "    \n",
    "img = cv.imread(\"images/lena.png\")\n",
    "salt_and_pepper(img, 0.03)"
   ],
   "id": "f01b555c2d98fc7d",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
